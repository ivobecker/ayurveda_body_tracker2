{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa06865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\signature\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d10d962f8740df8967a7ddbc61f242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\signature\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\signature\\.cache\\huggingface\\hub\\models--Qwen--Qwen-Image-Layered. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff99df77137419fbe3e0ef775ebd3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73e7f671b344700ada8034a823481f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62509bf48f249dd99d34175a7561782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/572 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b805b668e024492af362e818e307f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b712d57b5e8144b6bb767e2e009e09fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7748b6131f428080ef00fe235427bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ca6776ffb64cff87101a6c8982590a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff2ba558197483e94ce8d38f94725e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6320a092fae343d8aac7254a62e0f359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d431f79e3c14823aa9e432c83ae112f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor/tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf206251515400a864cfb5174053363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00002-of-00004.safete(…):   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9cb1ab8e044a7cb582ee6b68c6e2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17477a0e7cd5491e968ced40fd67d42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00001-of-00004.safete(…):   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a149f914a0458cb4e56552f3c8fd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cce337b98e4c32a357a9f10435ffa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511046e7690644638229f82c36d67d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00004-of-00004.safete(…):   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ce294821134fc2a182d7fb6c604e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00003-of-00004.safete(…):   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb57fb28c424ab5bc16e2f80fc6a462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ced19ab1e84a05acef053f56214631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d140b3b7d68e4a91991e27a00327a579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab180d6065c14f07bf72f45ea1786cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b682bd6ba63741339d4149622f15092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/424 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f086f47d96e54c6b9d3eb1721988233a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/9.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8eb2b18acec4f83ba293a1736639e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d4d2ae855c44f6a114ba9030fcbcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88c67d60a324b1cad7e10f7307d32df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformer/diffusion_pytorch_model-0000(…):   0%|          | 0.00/9.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import QwenImageLayeredPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "os.environ['KAGGLEHUB_CACHE'] = 'B:\\\\hf_cache\\\\kagglehub'\n",
    "\n",
    "model_path = kagglehub.model_download(\"qwen-lm/qwen-image-layered/transformers/qwen-image-layered\")\n",
    "#model_path = \"B:\\\\hf_cache\\\\kagglehub\\\\models\\\\qwen-lm\\\\qwen-image-layered\\\\transformers\\\\qwen-image-layered\\\\1\"\n",
    "# model_path is a local directory you can pass to from_pretrained()\n",
    "\n",
    "#pipeline = QwenImageLayeredPipeline.from_pretrained(model_path)\n",
    "pipeline = QwenImageLayeredPipeline.from_pretrained(\"Qwen/Qwen-Image-Layered\")\n",
    "\n",
    "    # Force CPU: use torch.float32 for CPU to avoid bfloat16 CUDA-only dtype\n",
    "pipeline = pipeline.to(\"cpu\", torch.float32)\n",
    "pipeline.set_progress_bar_config(disable=None)\n",
    "\n",
    "image = Image.open(\"B:\\\\OneDrive\\\\Documents\\\\ayurveda_yoga\\\\_praxis_forms_templates\\\\clinical_research_patient_1\\\\ayu_aitechnologies1\\\\IMG_0189.jpg\").convert(\"RGBA\")\n",
    "inputs = {\n",
    "    \"image\": image,\n",
    "    #\"generator\": torch.Generator(device='cuda').manual_seed(777),\n",
    "    \"generator\": torch.Generator(device='cpu').manual_seed(777),\n",
    "    \"true_cfg_scale\": 4.0,\n",
    "    \"negative_prompt\": \" \",\n",
    "    \"num_inference_steps\": 50,\n",
    "    \"num_images_per_prompt\": 1,\n",
    "    \"layers\": 4,\n",
    "    \"resolution\": 640,      # Using different bucket (640, 1024) to determine the resolution. For this version, 640 is recommended\n",
    "    \"cfg_normalize\": True,  # Whether enable cfg normalization.\n",
    "    \"use_en_prompt\": True,  # Automatic caption language if user does not provide caption\n",
    "}\n",
    "\n",
    "with torch.inference_mode():\n",
    "    output = pipeline(**inputs)\n",
    "    output_image = output.images[0]\n",
    "\n",
    "for i, image in enumerate(output_image):\n",
    "    image.save(f\"{i}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
